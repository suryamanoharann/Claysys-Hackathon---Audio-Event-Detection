{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14953322,"datasetId":9570543,"databundleVersionId":15823802},{"sourceType":"datasetVersion","sourceId":14837402,"datasetId":9489469,"databundleVersionId":15695981}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os, glob, re, gc, random\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torchaudio\nimport torchaudio.transforms as T\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\n# =============================================================================\n# 1. DIRECT PATHS\n# =============================================================================\nbase_path       = '/kaggle/input/datasets/surya5510/newdataset'\nfsd50k_dev_csv  = f\"{base_path}/dev.csv\"\nfsd50k_eval_csv = f\"{base_path}/eval.csv\"\nfsd50k_dev_dir  = f\"{base_path}/FSD50K.dev_audio/FSD50K.dev_audio/FSD50K.dev_audio\"\nfsd50k_eval_dir = f\"{base_path}/FSD50K.eval_audio/FSD50K.eval_audio\"\nlibrispeech_dir = f\"{base_path}/LibriSpeech/LibriSpeech/train-clean-100\"\n\n# =============================================================================\n# 2. NORMALIZATION FUNCTION\n# =============================================================================\ndef normalize_label(label):\n    label = str(label).lower()\n    label = label.replace('_and_', ' ').replace('_or_',  ' ')\n    label = label.replace('_', ' ').replace('-', ' ').replace('(', ' ').replace(')', ' ')\n    label = label.replace(',', ' ').replace('/', ' ').replace('.', ' ').replace(\"'\", ' ')\n    stopwords = {'and', 'or', 'the'}\n    words     = [w for w in label.split() if w not in stopwords]\n    return ' '.join(words).strip()\n\n# =============================================================================\n# 3. UPDATED 6-STEM CATEGORIZATION LOGIC\n# Resolves the ‚ùå None Errors by expanding the mapping for macro-stems.\n# =============================================================================\nLABEL_CONFLICT_RESOLUTION = {\n    'Speech':        1,  # Vocal Core\n    'Music':         2,  # Melodic/Harmonic\n    'Impacts':       3,  # Transients (Sharp vertical shapes)\n    'Alerts':        4,  # Sine-waves (Sustained horizontal shapes)\n    'Environmental': 5,  # Stochastic chaos (Nature + Animals + Crowd)\n    'Mechanical':    6,  # Periodic Drones (Mechanical + Domestic + Urban)\n}\n\nSTEMS = list(LABEL_CONFLICT_RESOLUTION.keys())\n\nLABEL_TO_SUPERCLASS_RAW = {\n    # ‚îÄ‚îÄ Speech ‚îÄ‚îÄ\n    'Speech': 'Speech', 'Male speech man speaking': 'Speech', \n    'Female speech woman speaking': 'Speech', 'Child speech kid speaking': 'Speech',\n    'Conversation': 'Speech', 'Whispering': 'Speech', 'Shout': 'Speech',\n\n    # ‚îÄ‚îÄ Music ‚îÄ‚îÄ\n    'Music': 'Music', 'Musical instrument': 'Music', 'Guitar': 'Music', \n    'Piano': 'Music', 'Drum': 'Music', 'Synthesizer': 'Music', 'Singing': 'Music',\n\n    # ‚îÄ‚îÄ Impacts (Transient Events) ‚îÄ‚îÄ\n    'Gunshot gunfire': 'Impacts', 'Explosion': 'Impacts', 'Bang': 'Impacts',\n    'Slam': 'Impacts', 'Knock': 'Impacts', 'Breaking': 'Impacts', \n    'Chink clink': 'Impacts',  # Resolved missing mapping\n\n    # ‚îÄ‚îÄ Alerts (Signaling Tones) ‚îÄ‚îÄ\n    'Alarm': 'Alerts', 'Siren': 'Alerts', 'Bell': 'Alerts', 'Chime': 'Alerts',\n    'Beep bleep': 'Alerts', 'Ringtone': 'Alerts', 'Telephone bell ringing': 'Alerts',\n\n    # ‚îÄ‚îÄ Environmental (Consolidated Nature/Animal/Crowd) ‚îÄ‚îÄ\n    'Bird': 'Environmental', 'Animal': 'Environmental', 'Dog': 'Environmental',\n    'Rain': 'Environmental', 'Wind': 'Environmental', 'Thunderstorm': 'Environmental',\n    'Crowd': 'Environmental', 'Applause': 'Environmental', 'Chatter': 'Environmental',\n    'Ocean': 'Environmental', 'Water': 'Environmental', 'Insect': 'Environmental',\n\n    # ‚îÄ‚îÄ Mechanical (Consolidated Urban/Domestic/Drones) ‚îÄ‚îÄ\n    'Engine': 'Mechanical', 'Vacuum cleaner': 'Mechanical', 'Chainsaw': 'Mechanical',\n    'Traffic noise roadway noise': 'Mechanical', 'Car': 'Mechanical', \n    'Train': 'Mechanical', 'Washing machine': 'Mechanical', 'Air conditioning': 'Mechanical',\n    'Bathtub filling washing': 'Mechanical', # Resolved missing mapping\n    'Sink filling washing': 'Mechanical',\n    'Water tap faucet': 'Mechanical'\n}\n\nNORMALIZED_MAP = {normalize_label(k): v for k, v in LABEL_TO_SUPERCLASS_RAW.items()}\nprint(f\"‚úÖ NORMALIZED_MAP built: {len(NORMALIZED_MAP)} entries\")\n\n# =============================================================================\n# 4. DUPLICATE VERIFICATION\n# =============================================================================\ndef verify_no_duplicates(raw_dict):\n    normalized_keys = [normalize_label(k) for k in raw_dict.keys()]\n    seen = {}\n    duplicates_found = False\n    for original, normalized in zip(raw_dict.keys(), normalized_keys):\n        if normalized in seen:\n            print(f\"‚ùå DUPLICATE: '{original}' collides with : '{seen[normalized]}'\")\n            duplicates_found = True\n        else:\n            seen[normalized] = original\n    if not duplicates_found:\n        print(\"‚úÖ No duplicates found in LABEL_TO_SUPERCLASS_RAW\")\n    return not duplicates_found\n\n# =============================================================================\n# 5. ASSIGN SUPERCLASS & LOAD\n# =============================================================================\ndef assign_superclass(labels_str):\n    full_normalized = normalize_label(labels_str)\n    words           = full_normalized.split()\n    superclasses    = []\n    i = 0\n    while i < len(words):\n        matched = False\n        for length in range(min(6, len(words) - i), 0, -1):\n            phrase     = ' '.join(words[i:i+length])\n            superclass = NORMALIZED_MAP.get(phrase)\n            if superclass:\n                superclasses.append(superclass)\n                i      += length\n                matched = True\n                break\n        if not matched: i += 1\n    if not superclasses: return None\n    return min(superclasses, key=lambda x: LABEL_CONFLICT_RESOLUTION[x])\n\ndef verify_normalization():\n    test_cases = [\n        ('Bird_vocalization_and_bird_call_and_bird_song', 'Environmental'),\n        ('Bathtub_(filling_or_washing)',                  'Mechanical'),\n        ('Traffic_noise,_roadway_noise',                  'Mechanical'),\n        ('Chink_and_clink',                               'Impacts'),\n        ('Child_speech_and_kid_speaking',                 'Speech'),\n        ('Smoke_detector,_smoke_alarm',                   'Alerts'),\n        ('Electric_guitar',                               'Music'),\n        ('Rain',                                          'Environmental'),\n        ('Gunshot_gunfire',                               'Impacts'),\n    ]\n    print(\"\\n\" + \"=\"*72 + \"\\n   6-STEM NORMALIZATION VERIFICATION\\n\" + \"=\"*72)\n    all_pass = True\n    for raw, expected in test_cases:\n        got = assign_superclass(raw)\n        ok = '‚úÖ' if got == expected else '‚ùå'\n        if got != expected: all_pass = False\n        print(f\"  {raw:<50} {expected:<15} {str(got):<15} {ok}\")\n    return all_pass\n\ndef load_and_merge_fsd50k_6stem(dev_csv, eval_csv, dev_dir, eval_dir):\n    all_noise = {stem: [] for stem in STEMS if stem != 'Speech'}\n    discarded = 0\n    df_all = pd.concat([pd.read_csv(dev_csv)[['fname', 'labels']], \n                        pd.read_csv(eval_csv)[['fname', 'labels']]], ignore_index=True)\n\n    for _, row in df_all.iterrows():\n        superclass = assign_superclass(row['labels'])\n        if not superclass or superclass == 'Speech':\n            discarded += 1\n            continue\n        path = os.path.join(dev_dir, str(row['fname']) + '.wav')\n        if not os.path.exists(path):\n            path = os.path.join(eval_dir, str(row['fname']) + '.wav')\n        if not os.path.exists(path):\n            discarded += 1\n            continue\n        all_noise[superclass].append(path)\n    print(f\"Total FSD50K clips after merge : {len(df_all)}\")\n    print(f\"Discarded (unknown label or missing file) : {discarded}\")\n    return all_noise\n\n# RUN EXECUTION\nverify_no_duplicates(LABEL_TO_SUPERCLASS_RAW)\nverify_normalization()\nnoise_data_raw = load_and_merge_fsd50k_6stem(fsd50k_dev_csv, fsd50k_eval_csv, fsd50k_dev_dir, fsd50k_eval_dir)\nspeech_files_raw = glob.glob(os.path.join(librispeech_dir, \"**/*.flac\"), recursive=True)\n\nprint(f\"\\nInventory Verified (6-Stem Pivot):\")\nprint(f\"‚úÖ Speech (Vocal Stem)  : {len(speech_files_raw)} files\")\nfor stem in STEMS:\n    if stem != 'Speech':\n        print(f\"‚úÖ {stem:<12} Stem   : {len(noise_data_raw[stem])} files\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:46:40.181393Z","iopub.execute_input":"2026-02-25T06:46:40.181725Z"}},"outputs":[{"name":"stdout","text":"‚úÖ NORMALIZED_MAP built: 51 entries\n‚úÖ No duplicates found in LABEL_TO_SUPERCLASS_RAW\n\n========================================================================\n   6-STEM NORMALIZATION VERIFICATION\n========================================================================\n  Bird_vocalization_and_bird_call_and_bird_song      Environmental   Environmental   ‚úÖ\n  Bathtub_(filling_or_washing)                       Mechanical      Mechanical      ‚úÖ\n  Traffic_noise,_roadway_noise                       Mechanical      Mechanical      ‚úÖ\n  Chink_and_clink                                    Impacts         Impacts         ‚úÖ\n  Child_speech_and_kid_speaking                      Speech          Speech          ‚úÖ\n  Smoke_detector,_smoke_alarm                        Alerts          Alerts          ‚úÖ\n  Electric_guitar                                    Music           Music           ‚úÖ\n  Rain                                               Environmental   Environmental   ‚úÖ\n  Gunshot_gunfire                                    Impacts         Impacts         ‚úÖ\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchaudio\nimport os\n\n# Ensure previous inventory is available\nprint(f\"6-Stem Noise categories found: {list(noise_data_raw.keys())}\")\n\n# Constants for purging logic\nSPEECH_DUR_THRESHOLD = 1.0\nNOISE_DUR_THRESHOLD  = 0.3\nRMS_THRESHOLD        = 0.005\n\ndef run_comprehensive_6stem_eda(speech_list, noise_dict, rms_threshold=0.005):\n    stats = []\n    print(\"üöÄ Performing 6-Stem Signal Integrity Audit...\")\n\n    # Consolidated 6-stem audit pool\n    audit_pool = {**noise_dict, 'Speech': speech_list}\n    \n    for cat, files in audit_pool.items():\n        cat_dur_threshold = SPEECH_DUR_THRESHOLD if cat == 'Speech' else NOISE_DUR_THRESHOLD\n        \n        # Sample 150 files per category for statistical significance\n        for f in files[:150]:\n            if not os.path.exists(f): \n                continue\n            try:\n                # Robust load (direct tensor calculation)\n                wav, sr = torchaudio.load(f)\n                \n                duration = wav.shape[1] / sr\n                rms_energy = torch.sqrt(torch.mean(wav**2)).item()\n                max_amp = torch.max(torch.abs(wav)).item()\n\n                stats.append({\n                    'Category': cat,\n                    'Duration': duration,\n                    'RMS_Energy': rms_energy,\n                    'Max_Amplitude': max_amp,\n                    'is_silent': rms_energy < rms_threshold,\n                    'is_too_short': duration < cat_dur_threshold\n                })\n            except Exception:\n                continue\n\n    df_eda = pd.DataFrame(stats)\n    \n    if df_eda.empty:\n        print(\"‚ùå ERROR: No audio files were successfully audited. Check paths.\")\n        return None\n\n    # --- VISUALIZATION SECTION ---\n    plt.figure(figsize=(20, 14))\n    sns.set_theme(style=\"whitegrid\")\n\n    # Plot 1: TRUE Dataset Distribution (Full Inventory counts)\n    plt.subplot(2, 2, 1)\n    true_counts = {\n        'Speech': len(speech_list),\n        **{k: len(v) for k, v in noise_dict.items()}\n    }\n    sns.barplot(x=list(true_counts.keys()), y=list(true_counts.values()), \n                hue=list(true_counts.keys()), palette='magma', legend=False)\n    plt.yscale('log')\n    plt.xticks(rotation=45, ha='right')\n    plt.title(\"2.a: 6-Stem TRUE Dataset Distribution (Log Scale)\")\n    plt.ylabel(\"Number of Files\")\n\n    # Plot 2: Duration Audit (Visualizing purging boundaries)\n    plt.subplot(2, 2, 2)\n    sns.boxplot(data=df_eda, x='Category', y='Duration', hue='Category', palette='Set2', legend=False)\n    plt.axhline(y=SPEECH_DUR_THRESHOLD, color='red', linestyle='--', label='Min Speech')\n    plt.axhline(y=NOISE_DUR_THRESHOLD, color='orange', linestyle='--', label='Min Noise')\n    plt.title(\"2.b: Duration Integrity Audit\")\n    plt.legend()\n\n    # Plot 3: Signal Integrity (RMS Energy - Slider Hiding Proof)\n    plt.subplot(2, 2, 3)\n    sns.stripplot(data=df_eda, x='Category', y='RMS_Energy', \n                  hue='is_silent', palette={True: 'red', False: 'skyblue'},\n                  jitter=0.2, alpha=0.7)\n    plt.axhline(y=rms_threshold, color='red', linestyle='--', label='UI Silence Threshold')\n    plt.title(\"2.c: RMS Energy (Used for Dynamic UI Hiding)\")\n    plt.legend(title=\"Outlier Status\")\n\n    # Plot 4: Dynamic Range per Macro-Stem\n    plt.subplot(2, 2, 4)\n    sns.violinplot(data=df_eda, x='Category', y='Max_Amplitude', hue='Category',\n                   inner=\"quart\", palette='coolwarm', legend=False)\n    plt.title(\"2.d: Dynamic Range (Amplitude) Analysis\")\n\n    plt.tight_layout()\n    plt.show()\n\n    # --- SUMMARY REPORT ---\n    print(\"\\n\" + \"=\"*50)\n    print(\"6-STEM EDA SUMMARY FOR PROJECT DOCUMENTATION\")\n    print(\"=\"*50)\n    print(f\"Total Silence Outliers Detected (Sample): {df_eda['is_silent'].sum()}\")\n    print(f\"Total Short Outliers Detected (Sample)  : {df_eda['is_too_short'].sum()}\")\n    print(\"\\nAverage Duration per Macro-Category (Seconds):\")\n    print(df_eda.groupby('Category')['Duration'].mean().round(2))\n\n    return df_eda\n\n# Execute the 6-stem Audit\neda_results = run_comprehensive_6stem_eda(speech_files_raw, noise_data_raw)\n\ndef report_6stem_outlier_sources(df_eda):\n    if df_eda is None: return\n    \n    print(\"\\n\" + \"=\"*50)\n    print(\"6-STEM OUTLIER SOURCE REPORT\")\n    print(\"=\"*50)\n\n    df_eda['Source_Dataset'] = df_eda['Category'].apply(\n        lambda x: 'LibriSpeech' if x == 'Speech' else 'FSD50K'\n    )\n\n    source_report = df_eda.groupby('Source_Dataset').agg({\n        'is_silent': 'sum',\n        'is_too_short': 'sum'\n    }).rename(columns={'is_silent': 'Silent_Files', 'is_too_short': 'Short_Files'})\n\n    print(source_report)\n\n    for source in source_report.index:\n        total = len(df_eda[df_eda['Source_Dataset'] == source])\n        outliers = source_report.loc[source].sum()\n        integrity = ((total - outliers) / total) * 100\n        print(f\"\\n{source} Sample Integrity Rate: {integrity:.2f}%\")\n\n# Run Source Report\nreport_6stem_outlier_sources(eda_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.968462Z","iopub.status.idle":"2026-02-25T06:45:37.968781Z","shell.execute_reply.started":"2026-02-25T06:45:37.968649Z","shell.execute_reply":"2026-02-25T06:45:37.968667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torchaudio\nimport os\n\n# =============================================================================\n# 6-STEM COMPREHENSIVE AUDIT & STATS (Unified)\n# =============================================================================\ndef run_unified_6stem_analysis(speech_list, noise_dict, rms_threshold=0.005):\n    stats = []\n    print(\"üöÄ Initializing 6-Stem Signal Integrity Audit...\")\n\n    # Pool speech + 5 noise macro-stems\n    audit_pool = {**noise_dict, 'Speech': speech_list}\n    \n    for cat, files in audit_pool.items():\n        cat_dur_threshold = SPEECH_DUR_THRESHOLD if cat == 'Speech' else NOISE_DUR_THRESHOLD\n        \n        # Audit a robust sample of 150 files per category\n        for f in files[:150]:\n            if not os.path.exists(f): continue\n            try:\n                # Direct load to bypass 'info' attribute errors\n                wav, sr = torchaudio.load(f)\n                duration = wav.shape[1] / sr\n                rms_energy = torch.sqrt(torch.mean(wav**2)).item()\n                max_amp = torch.max(torch.abs(wav)).item()\n\n                stats.append({\n                    'Category': cat,\n                    'Duration': duration,\n                    'RMS_Energy': rms_energy,\n                    'Max_Amplitude': max_amp,\n                    'is_silent': rms_energy < rms_threshold,\n                    'is_too_short': duration < cat_dur_threshold\n                })\n            except: continue\n\n    # Create DataFrame in the local scope\n    df_results = pd.DataFrame(stats)\n\n    if df_results.empty:\n        print(\"‚ùå CRITICAL ERROR: No data was collected. Check Section 1 Paths!\")\n        return None\n\n\n\n    # --- 2. STATISTICAL TABLE ---\n    print(\"\\n\" + \"=\"*65)\n    print(\"--- 6-STEM TEMPORAL STATISTICAL SUMMARY (SECONDS) ---\")\n    print(\"=\" * 65)\n    \n    stats_table = df_results.groupby('Category')['Duration'].agg(['mean', 'median', 'std']).round(2)\n    stats_table = stats_table.fillna(0.00)\n    stats_table.columns = ['Mean (s)', 'Median (s)', 'Std Dev (œÉ)']\n    \n    print(stats_table)\n    print(\"=\" * 65)\n    \n    return df_results # This ensures 'eda_results' is populated in main memory\n\n# --- EXECUTION ---\nif 'speech_files_raw' in locals() and 'noise_data_raw' in locals():\n    # We assign the output to 'eda_results' globally\n    eda_results = run_unified_6stem_analysis(speech_files_raw, noise_data_raw)\nelse:\n    print(\"‚ùå Error: Inventory variables not found. Run the Section 1 Path cell first!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.969635Z","iopub.status.idle":"2026-02-25T06:45:37.969880Z","shell.execute_reply.started":"2026-02-25T06:45:37.969767Z","shell.execute_reply":"2026-02-25T06:45:37.969782Z"}},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"for the report EDA","metadata":{}},{"cell_type":"code","source":"# =============================================================================\n# SECTION 3: TECHNICAL CONSISTENCY AUDIT (Generates Fig 3.3 Data)\n# =============================================================================\nimport torchaudio\nimport random\nimport torch\n\ndef run_technical_consistency_audit_6stem(speech_files, noise_dict, sample_limit=200):\n    print(\"üöÄ Starting 6-Stem Technical Consistency Audit (Robust Mode)...\")\n    \n    # Store unique properties for report narrative\n    found_sample_rates = set()\n    found_channels = set()\n    \n    # Combine noise stems for general sampling\n    all_noise_files = [f for sublist in noise_dict.values() for f in sublist]\n    \n    # Check a subset of Speech (LibriSpeech) and Noise (FSD50K)\n    # We load the tensor directly to ensure version compatibility\n    audit_pool = speech_files[:sample_limit] + random.sample(all_noise_files, min(sample_limit, len(all_noise_files)))\n    \n    for f in audit_pool:\n        try:\n            # We only load the first few samples to stay fast\n            wav, sr = torchaudio.load(f)\n            found_sample_rates.add(sr)\n            found_channels.add(wav.shape[0]) # wav.shape[0] is num_channels\n        except: \n            continue\n\n    print(\"\\n\" + \"=\"*50)\n    print(\"3. Technical Consistency Verification Logs\")\n    print(\"=\"*50)\n    print(f\"Original Sample Rates found  : {sorted(list(found_sample_rates))} Hz\")\n    print(f\"Original Channel counts found: {sorted(list(found_channels))}\")\n    print(\"-\" * 50)\n    \n    # --- AUTOMATED NARRATIVE LOGIC ---\n    # These strings can be copied directly into your project report\n    if len(found_sample_rates) > 1:\n        print(\">> STATUS: Frequency Variance Detected (Mismatched Sample Rates).\")\n        print(\"   RATIONALE: Unified 16kHz resampling is REQUIRED for tensor alignment.\")\n    else:\n        print(\">> STATUS: Sample rates are unified.\")\n\n    if 1 in found_channels:\n        print(\">> STATUS: Mono Source Detected.\")\n        print(\"   RATIONALE: Stereo up-mixing (repeat channel) is REQUIRED for 2-ch UI output.\")\n    \n    if any(sr > 16000 for sr in found_sample_rates):\n        print(\">> STATUS: High-Fidelity sources detected (>16kHz).\")\n        print(\"   RATIONALE: Low-pass filtering during resampling will prevent aliasing.\")\n    print(\"=\" * 50)\n\n# Execute Audit\nif 'speech_files_raw' in locals() and 'noise_data_raw' in locals():\n    run_technical_consistency_audit_6stem(speech_files_raw, noise_data_raw)\nelse:\n    print(\"‚ùå Error: Dataset lists not found. Run the '6-Stem Pivot & Inventory' step first.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.970969Z","iopub.status.idle":"2026-02-25T06:45:37.971201Z","shell.execute_reply.started":"2026-02-25T06:45:37.971095Z","shell.execute_reply":"2026-02-25T06:45:37.971109Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport torch\nimport torchaudio\nimport os\nimport pickle\n\n# =============================================================================\n# 4. 6-STEM STRATIFIED CLEANING & SPLITTING (RECORD-LEVEL)\n# =============================================================================\n\ndef clean_and_split_6stem(file_list, name, dur_threshold, rms_threshold=0.005):\n    \"\"\"\n    Performs cleaning and independent record-level splitting.\n    Ensures rare stems (Mechanical/Impacts) are preserved in val/test.\n    \"\"\"\n    vetted = []\n    print(f\"Purging outliers from {name}...\")\n\n    for f in file_list:\n        try:\n            if not os.path.exists(f): continue\n            \n            # Robust Load: Direct tensor calculation for duration & RMS\n            wav, sr = torchaudio.load(f)\n            duration = wav.shape[1] / sr\n            \n            # Filter 1: Temporal Integrity\n            if duration < dur_threshold: continue\n            \n            # Filter 2: Signal Integrity (RMS Silence Purge)\n            rms_energy = torch.sqrt(torch.mean(wav**2)).item()\n            if rms_energy < rms_threshold: continue\n\n            vetted.append(f)\n        except Exception:\n            continue \n\n    # SAFETY CHECK: If a stem is critically small, keep all in Train\n    if len(vetted) < 20:\n        print(f\"  ‚ö†Ô∏è WARNING: {name} has only {len(vetted)} clips. Assigning all to train.\")\n        return vetted, [], []\n\n    # RECORD-LEVEL SPLIT: Performed independently for this stem\n    # Prevents common stems (Speech/Music) from dominating val/test pools\n    train, temp = train_test_split(vetted, test_size=0.2, random_state=42)\n    val, test   = train_test_split(temp,   test_size=0.5, random_state=42)\n\n    print(f\"Done! {name} Final Count: {len(vetted)} (Cleaned)\")\n    print(f\"      Train: {len(train)} | Val: {len(val)} | Test: {len(test)}\")\n    return train, val, test\n\n# ‚îÄ‚îÄ 1. Split Speech (Vocal Stem) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n# LibriSpeech: ~28k files handled as one record pool\nv_train, v_val, v_test = clean_and_split_6stem(\n    speech_files_raw, \"Speech\", SPEECH_DUR_THRESHOLD\n)\n\n# ‚îÄ‚îÄ 2. Split 5 Noise Macro-Stems ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n# Independent splitting for Music, Impacts, Alerts, Environmental, Mechanical\nnoise_split = {}\nfor cat, files in noise_data_raw.items():\n    tr, va, te = clean_and_split_6stem(files, cat, NOISE_DUR_THRESHOLD)\n    noise_split[cat] = {'train': tr, 'val': va, 'test': te}\n\n# ‚îÄ‚îÄ 3. Persistence & Verification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nOUTPUT_DIR = \"/kaggle/working/6stem_splits_dataset\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nfinal_data = {\n    'v_train': v_train, 'v_val': v_val, 'v_test': v_test,\n    'noise_split': noise_split\n}\n\nwith open(f\"{OUTPUT_DIR}/6stem_splits.pkl\", \"wb\") as f:\n    pickle.dump(final_data, f)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\">>> LEVEL 1 COMPLETE: All sets are vetted and ready for the Mixer.\")\nprint(\"=\"*60)\nprint(f\"Speech Stats  : {len(v_train)} train | {len(v_val)} val | {len(v_test)} test\")\nfor stem, splits in noise_split.items():\n    print(f\"{stem:<14}: {len(splits['train'])} train | {len(splits['val'])} val | {len(splits['test'])} test\")\n\n# ‚îÄ‚îÄ Safety Assertions ‚îÄ‚îÄ\nassert len(v_train) > 0, \"v_train is empty\"\nassert len(noise_split) == 5, f\"Expected 5 noise stems, found {len(noise_split)}\"\nprint(\"\\n>>> All variables confirmed. Safe to run SonicMixer cell.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.973173Z","iopub.status.idle":"2026-02-25T06:45:37.973467Z","shell.execute_reply.started":"2026-02-25T06:45:37.973347Z","shell.execute_reply":"2026-02-25T06:45:37.973365Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"till split","metadata":{}},{"cell_type":"code","source":"import pickle\nimport os\n\n# =============================================================================\n# 5. PERSISTENCE: SECURE 6-STEM CLEANED SPLITS\n# =============================================================================\n\n# 1. Define the output directory\nOUTPUT_DIR = \"/kaggle/working/6stem_splits_dataset\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# --- PRE-SAVE VALIDATION ---\n# This checks if your variables are named correctly from the previous cell\ntry:\n    # If your splitting loop used 'noise_split', we assign it here\n    current_noise_data = noise_split \nexcept NameError:\n    try:\n        # If it was named 'noise_6stem_split', we use that instead\n        current_noise_data = noise_6stem_split\n    except NameError:\n        print(\"‚ùå ERROR: Could not find your noise split variable.\")\n        print(\"Please check the name of the dictionary in your splitting cell.\")\n        current_noise_data = None\n\nif current_noise_data:\n    # 2. Package the 6-stem data with a 'Mapping' key\n    splits_data = {\n        'metadata': {\n            'architecture': '6-stem-pivot',\n            'order': ['Speech', 'Music', 'Impacts', 'Alerts', 'Environmental', 'Mechanical'],\n            'sample_rate': 16000\n        },\n        'v_train': v_train,\n        'v_val': v_val,\n        'v_test': v_test,\n        'noise_split': current_noise_data \n    }\n\n    # 3. Save as binary pickle file\n    save_path = f\"{OUTPUT_DIR}/6stem_splits.pkl\"\n    with open(save_path, \"wb\") as f:\n        pickle.dump(splits_data, f)\n\n    # 4. Generate the 'Technical Audit' README for your Project Report\n    with open(f\"{OUTPUT_DIR}/6STEM_AUDIT_LOG.txt\", \"w\") as f:\n        f.write(\"6-STEM AUDIO SEPARATION: PREPROCESSED DATASET AUDIT\\n\")\n        f.write(\"=\"*65 + \"\\n\")\n        f.write(f\"Vocal (Speech) Partition: {len(v_train)} Train | {len(v_val)} Val | {len(v_test)} Test\\n\")\n        f.write(\"-\" * 65 + \"\\n\\n\")\n        \n        f.write(\"Noise Macro-Stem Partitions (Stratified):\\n\")\n        f.write(f\"{'Stem Name':<18} | {'Train':<8} | {'Val':<8} | {'Test':<8}\\n\")\n        f.write(\"-\" * 65 + \"\\n\")\n        for stem, splits in current_noise_data.items():\n            f.write(f\"{stem:<18} | {len(splits['train']):<8} | {len(splits['val']):<8} | {len(splits['test']):<8}\\n\")\n        \n        f.write(\"\\n\" + \"=\"*65 + \"\\n\")\n        f.write(\"Preprocessing logic: RMS Threshold > 0.005 | Stereo Up-mix Ready\\n\")\n\n    print(f\"‚úÖ 6-Stem Splits & Audit Log secured in: {OUTPUT_DIR}\")\n    \n    # --- KAGGLE PERSISTENCE INSTRUCTIONS ---\n    print(\"\\n\" + \"!\"*50)\n    print(\"CRITICAL ACTION REQUIRED FOR DATA PERSISTENCE:\")\n    print(\"1. Refresh the 'Output' folder in the Kaggle sidebar.\")\n    print(\"2. Download '6stem_splits.pkl'.\")\n    print(\"3. Add this .pkl as a NEW dataset to bypass auditing later.\")\n    print(\"!\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.975596Z","iopub.status.idle":"2026-02-25T06:45:37.975891Z","shell.execute_reply.started":"2026-02-25T06:45:37.975747Z","shell.execute_reply":"2026-02-25T06:45:37.975766Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"saved splitted file","metadata":{}},{"cell_type":"code","source":"import pickle\nimport os\n\n# =============================================================================\n# ONE-TIME SCRIPT: SAVE 6-STEM CLEANED SPLITS\n# \n# Run this after Section 2 (Cleaning & Splitting) finishes.\n# This permanently stores your 6-stem architecture (1 Speech + 5 Noise).\n# =============================================================================\n\n# Define the output directory\nOUTPUT_DIR = \"/kaggle/working/6stem_splits_dataset\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n# Package the 6-stem data\n# Using 'noise_6stem_split' from the previous cell\nsplits_data = {\n    'v_train': v_train,\n    'v_val': v_val,\n    'v_test': v_test,\n    'noise_split': noise_6stem_split # Updated reference\n}\n\n# Save as binary pickle file (Fastest for Python)\nsave_path = f\"{OUTPUT_DIR}/6stem_splits.pkl\"\nwith open(save_path, \"wb\") as f:\n    pickle.dump(splits_data, f)\n\n# Also save a human-readable summary for your Project Report\nwith open(f\"{OUTPUT_DIR}/6STEM_README.txt\", \"w\") as f:\n    f.write(\"6-STEM ARCHITECTURE: CLEANED AUDIO SPLITS\\n\")\n    f.write(\"=\"*60 + \"\\n\\n\")\n    f.write(f\"Vocal (Speech) train : {len(v_train)} files\\n\")\n    f.write(f\"Vocal (Speech) val   : {len(v_val)} files\\n\")\n    f.write(f\"Vocal (Speech) test  : {len(v_test)} files\\n\\n\")\n    \n    f.write(\"Noise Macro-Stems:\\n\")\n    f.write(\"-\" * 20 + \"\\n\")\n    for stem, splits in noise_6stem_split.items():\n        f.write(f\"{stem:<15}: train={len(splits['train']):<6} \"\n                f\"val={len(splits['val']):<6} test={len(splits['test'])}\\n\")\n\nprint(f\"‚úÖ 6-Stem splits saved to: {OUTPUT_DIR}\")\nprint(\"\\n\" + \"!\"*40)\nprint(\"CRITICAL NEXT STEPS FOR PERSISTENCE:\")\nprint(\"1. In the right-hand panel of Kaggle, find 'Output'.\")\nprint(\"2. Download '6stem_splits.pkl'.\")\nprint(\"3. Click '+ Add Data' -> 'New Dataset'.\")\nprint(\"4. Name it: '6stem-audio-splits' and upload the .pkl file.\")\nprint(\"5. Link that new dataset to this notebook.\")\nprint(\"!\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.977056Z","iopub.status.idle":"2026-02-25T06:45:37.977352Z","shell.execute_reply.started":"2026-02-25T06:45:37.977219Z","shell.execute_reply":"2026-02-25T06:45:37.977238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport json\nimport shutil\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchaudio.models import HDemucs\n\n# =============================================================================\n# SECTION 8: MODEL INITIALIZATION (6-STEM PIVOT)\n# =============================================================================\n\n# ‚îÄ‚îÄ 1. Device Configuration ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\">>> Device: {DEVICE}\")\nif DEVICE.type == 'cuda':\n    print(f\">>> GPU   : {torch.cuda.get_device_name(0)}\")\n    print(f\">>> VRAM  : {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n\n# ‚îÄ‚îÄ 2. Persistence & Kaggle API Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nos.makedirs(\"/root/.config/kaggle\", exist_ok=True)\ncreds = {\n    \"username\": \"surya5510\",\n    \"key\": \"KGAT_680693999b61b942df6967cf0ef695e3\" # Your current active key\n}\nwith open(\"/root/.config/kaggle/kaggle.json\", \"w\") as f:\n    json.dump(creds, f)\nos.chmod(\"/root/.config/kaggle/kaggle.json\", 0o600)\n\n# Updated dataset targets for 6-stem version\nKAGGLE_USERNAME = \"surya5510\"\nDATASET_NAME    = \"start-6stem\"\nDATASET_SLUG    = f\"{KAGGLE_USERNAME}/{DATASET_NAME}\"\nFILENAME        = \"sonic_separator_6stem.pth\"\nBEST_FILENAME   = \"sonic_separator_6stem_best.pth\"\nSTAGING_DIR     = \"/kaggle/working/ckpt_staging\"\n\nWORKING_PATH    = f\"/kaggle/working/{FILENAME}\"\nBEST_PATH       = f\"/kaggle/working/{BEST_FILENAME}\"\nPERSISTENT_PATH = f\"/kaggle/input/{DATASET_NAME}/{FILENAME}\"\n\ndef push_to_dataset(local_path, filename):\n    \"\"\"Survives Kaggle session timeouts by pushing to persistent dataset.\"\"\"\n    try:\n        os.makedirs(STAGING_DIR, exist_ok=True)\n        shutil.copy2(local_path, os.path.join(STAGING_DIR, filename))\n        meta = {\n            \"title\": DATASET_NAME,\n            \"id\": DATASET_SLUG,\n            \"licenses\": [{\"name\": \"CC0-1.0\"}]\n        }\n        with open(os.path.join(STAGING_DIR, \"dataset-metadata.json\"), \"w\") as f:\n            json.dump(meta, f)\n        \n        # Versioning push\n        ret = os.system(f\"kaggle datasets version -p {STAGING_DIR} -m '6-stem auto-checkpoint' --dir-mode zip\")\n        if ret == 0:\n            print(f\"  >>> [PUSHED] {filename} ‚úÖ\")\n        else:\n            print(f\"  >>> [PUSH FAILED] CLI {ret}\")\n    except Exception as e:\n        print(f\"  >>> [PUSH FAILED] {e}\")\n\n# ‚îÄ‚îÄ 3. 6-Stem Architecture Definition ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n# Consolidated for better SDR and unique acoustic signatures\nSTEMS = ['Speech', 'Music', 'Impacts', 'Alerts', 'Environmental', 'Mechanical']\n\nmodel = HDemucs(sources=STEMS, audio_channels=2)\nmodel = nn.DataParallel(model).to(DEVICE)\n\n# ‚îÄ‚îÄ 4. Optimization & Checkpoint Resume ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n\nstart_epoch   = 0\nbest_val_loss = float('inf')\n\n# Check for persistent 6-stem checkpoint\nif os.path.exists(WORKING_PATH):\n    load_path = WORKING_PATH\nelif os.path.exists(PERSISTENT_PATH):\n    load_path = PERSISTENT_PATH\n    shutil.copy2(PERSISTENT_PATH, WORKING_PATH)\nelse:\n    load_path = None\n\nif load_path:\n    ckpt = torch.load(load_path, map_location=DEVICE)\n    model.module.load_state_dict(ckpt['model'])\n    optimizer.load_state_dict(ckpt['opt'])\n    scheduler.load_state_dict(ckpt['scheduler'])\n    start_epoch   = ckpt.get('epoch', 0)\n    best_val_loss = ckpt.get('best_val_loss', float('inf'))\n    print(f\">>> RESUMING 6-STEM MODEL: Epoch {start_epoch + 1}\")\n\n# ‚îÄ‚îÄ Summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nprint(f\"\\n{'='*52}\")\nprint(f\"  MODEL INITIALIZED: 6-STEM MACRO ARCHITECTURE\")\nprint(f\"{'='*52}\")\nprint(f\"  Targets (1:1:1): {', '.join(STEMS)}\")\nprint(f\"  Loss Function  : Equal-Weight SI-SDR\")\nprint(f\"  Persist Target : {DATASET_SLUG}\")\nprint(f\"  VRAM Savings   : ~40% vs 10-stem version\")\nprint(f\"{'='*52}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.978332Z","iopub.status.idle":"2026-02-25T06:45:37.978577Z","shell.execute_reply.started":"2026-02-25T06:45:37.978450Z","shell.execute_reply":"2026-02-25T06:45:37.978463Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport torch\n\n# ‚îÄ‚îÄ DEFINING DEVICE LOCALLY TO PREVENT NAME ERRORS ‚îÄ‚îÄ\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# =============================================================================\n# SECTION 9: 6-STEM TRAINING LOOP (Equal-Weight SI-SDR Edition)\n# Optimized for 16,000Hz Stereo | 6 Stems | Equal-Weight SI-SDR Loss\n# =============================================================================\n\ndef equal_weight_sisdr_loss(estimate, target, eps=1e-8):\n    \"\"\"\n    Scale-Invariant Signal-to-Distortion Ratio (SI-SDR).\n    Maximizes clarity and enforces zero bias across all 6 stems.\n    \"\"\"\n    # Flatten spatial dimensions: [Batch, Stems, Channels, Time] -> [Batch, Stems, Channels*Time]\n    est = estimate.reshape(estimate.shape[0], estimate.shape[1], -1)\n    tgt = target.reshape(target.shape[0], target.shape[1], -1)\n\n    # Zero-mean the signals to remove DC offset\n    est = est - est.mean(dim=-1, keepdim=True)\n    tgt = tgt - tgt.mean(dim=-1, keepdim=True)\n\n    # Compute optimal scaling factor (alpha)\n    alpha = (est * tgt).sum(dim=-1, keepdim=True) / ((tgt ** 2).sum(dim=-1, keepdim=True) + eps)\n    \n    # Project target and calculate noise/distortion\n    tgt_scaled = alpha * tgt\n    noise = est - tgt_scaled\n    \n    # Calculate SI-SDR\n    signal_energy = (tgt_scaled ** 2).sum(dim=-1)\n    noise_energy = (noise ** 2).sum(dim=-1)\n    sisdr = 10 * torch.log10(signal_energy / (noise_energy + eps) + eps)\n    \n    # Return negative mean (since optimizers minimize loss, we minimize negative SI-SDR)\n    return -sisdr.mean()\n\nprint(f\"üöÄ Starting 6-Stem Training on {DEVICE}...\")\nprint(f\"Epochs       : {start_epoch + 1} ‚Üí 50\")\nprint(f\"Stems        : {', '.join(STEMS)}\")\nprint(f\"Loss Target  : Equal-Weight SI-SDR (Minimizing)\")\nprint(f\"Train batches: {len(train_loader):,} per epoch\")\nprint(f\"Val batches  : {len(val_loader):,} per epoch\")\nprint(f\"{'='*52}\")\n\nfor epoch in range(start_epoch, 50):\n\n    # ‚îÄ‚îÄ 1. TRAIN PHASE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    model.train()\n    train_loss_accum = 0.0\n    train_batches    = 0\n\n    for i, (mix, target) in enumerate(train_loader):\n        mix    = mix.to(DEVICE)       # Mixture [4, 2, 32000]\n        target = target.to(DEVICE)    # Targets [4, 6, 2, 32000]\n\n        optimizer.zero_grad()\n        \n        # Forward pass\n        est = model(mix)              # Estimated stems [4, 6, 2, 32000]\n        \n        # Apply the unbiased SI-SDR loss\n        loss = equal_weight_sisdr_loss(est, target)\n        \n        loss.backward()\n        optimizer.step()\n\n        train_loss_accum += loss.item()\n        train_batches    += 1\n\n        # Periodic Progress Update\n        if i % 100 == 0:\n            avg = train_loss_accum / train_batches\n            lr  = optimizer.param_groups[0]['lr']\n            print(f\"Epoch {epoch+1:02d} | Batch {i:>5}/{len(train_loader)} | \"\n                  f\"Loss: {loss.item():.4f} | Avg: {avg:.4f} | LR: {lr:.7f}\")\n\n        # ‚îÄ‚îÄ CRASH SAVE (Every 1500 batches) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n        # Pushes to 'start-6stem' dataset to survive session disconnects\n        if i > 0 and i % 1500 == 0:\n            torch.save({\n                'epoch'        : epoch,\n                'batch'        : i,\n                'model'        : model.module.state_dict(),\n                'opt'          : optimizer.state_dict(),\n                'scheduler'    : scheduler.state_dict(),\n                'best_val_loss': best_val_loss,\n            }, WORKING_PATH)\n            \n            torch.cuda.empty_cache()\n            gc.collect()\n            \n            push_to_dataset(WORKING_PATH, FILENAME)\n            print(f\"  --- [SAFE SAVE] Batch {i} secured to Kaggle Dataset ---\")\n\n    epoch_train_loss = train_loss_accum / train_batches\n\n    # ‚îÄ‚îÄ 2. VALIDATION PHASE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    # Uses fixed mixing (augment=False) for consistent benchmarking\n    model.eval()\n    val_loss_accum = 0.0\n    val_batches    = 0\n\n    with torch.no_grad():\n        for mix_v, target_v in val_loader:\n            mix_v    = mix_v.to(DEVICE)\n            target_v = target_v.to(DEVICE)\n            \n            est_v   = model(mix_v)\n            loss_v  = equal_weight_sisdr_loss(est_v, target_v)\n            \n            val_loss_accum += loss_v.item()\n            val_batches    += 1\n\n    epoch_val_loss = val_loss_accum / val_batches\n\n    # ‚îÄ‚îÄ 3. SCHEDULER & PERSISTENCE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    scheduler.step()\n    new_lr = optimizer.param_groups[0]['lr']\n\n    # Check for improvement\n    improved = epoch_val_loss < best_val_loss\n    if improved:\n        best_val_loss = epoch_val_loss\n        torch.save({\n            'epoch'        : epoch + 1,\n            'model'        : model.module.state_dict(),\n            'opt'          : optimizer.state_dict(),\n            'scheduler'    : scheduler.state_dict(),\n            'best_val_loss': best_val_loss,\n        }, BEST_PATH)\n        push_to_dataset(BEST_PATH, BEST_FILENAME)\n        best_tag = '  *** BEST ***'\n    else:\n        best_tag = ''\n\n    # End of Epoch \"Baton Pass\" Checkpoint\n    torch.save({\n        'epoch'        : epoch + 1,\n        'model'        : model.module.state_dict(),\n        'opt'          : optimizer.state_dict(),\n        'scheduler'    : scheduler.state_dict(),\n        'best_val_loss': best_val_loss,\n    }, WORKING_PATH)\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n    push_to_dataset(WORKING_PATH, FILENAME)\n\n    # ‚îÄ‚îÄ 4. EPOCH SUMMARY ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n    print(f\"\\n{'='*52}\")\n    print(f\"  EPOCH {epoch+1:02d} COMPLETE\")\n    print(f\"  Train SI-SDR Loss : {epoch_train_loss:.4f}\")\n    print(f\"  Val SI-SDR Loss   : {epoch_val_loss:.4f}{best_tag}\")\n    print(f\"  Best Val          : {best_val_loss:.4f}\")\n    print(f\"  LR after          : {new_lr:.7f}\")\n    print(f\"{'='*52}\\n\")\n\nprint(\"‚úÖ 6-STEM TRAINING COMPLETE\")\nprint(f\">>> Best Val SI-SDR: {best_val_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.982234Z","iopub.status.idle":"2026-02-25T06:45:37.982590Z","shell.execute_reply.started":"2026-02-25T06:45:37.982395Z","shell.execute_reply":"2026-02-25T06:45:37.982415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":">>> Device: cpu\n\n====================================================\n  MODEL INITIALIZED: 6-STEM MACRO ARCHITECTURE\n====================================================\n  Targets (1:1:1): Speech, Music, Impacts, Alerts, Environmental, Mechanical\n  Loss Function  : Equal-Weight SI-SDR\n  Persist Target : surya5510/start-6stem\n  VRAM Savings   : ~40% vs 10-stem version\n====================================================","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-25T06:45:37.985205Z","iopub.status.idle":"2026-02-25T06:45:37.985450Z","shell.execute_reply.started":"2026-02-25T06:45:37.985330Z","shell.execute_reply":"2026-02-25T06:45:37.985344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}